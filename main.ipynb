{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\emila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\emila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing libraries\n",
    "import wikipediaapi\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "#NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization and preprocessing\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "def apply_stemming(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "def construct_bag_of_words(tokens):\n",
    "    text = ' '.join(tokens)\n",
    "    vectorizer = CountVectorizer()\n",
    "    bow_representation = vectorizer.fit_transform([text])\n",
    "    return bow_representation.toarray()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing input\n",
    "def divide_into_slices(input_text, standard_size):\n",
    "    tokens = tokenize_text(input_text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = apply_stemming(tokens)\n",
    "    bag_of_words = construct_bag_of_words(tokens)\n",
    "    \n",
    "    if len(bag_of_words) <= standard_size:\n",
    "        return [bag_of_words]\n",
    "    \n",
    "    # otherwise, divide the processed input\n",
    "    num_slices = len(bag_of_words) // standard_size + 1\n",
    "    slice_size = len(bag_of_words) // num_slices\n",
    "    slices = [bag_of_words[i:i+slice_size] for i in range(0, len(bag_of_words), slice_size)]\n",
    "    \n",
    "    return slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Distance Calculation\n",
    "def calculate_cosine_distance(slice1, slice2):\n",
    "    similarity_matrix = cosine_similarity(np.array(slice1).reshape(1, -1), np.array(slice2).reshape(1, -1))\n",
    "    cosine_distance = 1 - similarity_matrix[0, 0]\n",
    "    return cosine_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Slicing Criteria\n",
    "def check_slicing_criteria(slices, cosine_distance_threshold=0.2):\n",
    "    new_slices = [slices[0]] \n",
    "\n",
    "    for i in range(1, len(slices)):\n",
    "        current_slice = slices[i]\n",
    "        previous_slice = new_slices[-1]\n",
    "\n",
    "        # checking slices overlaping\n",
    "        if current_slice[0] >= previous_slice[-1]:\n",
    "            new_slices.append(current_slice)\n",
    "        else:\n",
    "            distance = calculate_cosine_distance(previous_slice, current_slice)\n",
    "\n",
    "            if distance > cosine_distance_threshold:\n",
    "                new_slices[-1] = current_slice\n",
    "\n",
    "    return new_slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP Pipeline\n",
    "def nlp_pipeline(input_text, standard_size=128, cosine_distance_threshold=0.2):\n",
    "    tokens = tokenize_text(input_text)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = apply_stemming(tokens)\n",
    "    bag_of_words = construct_bag_of_words(tokens)\n",
    "    \n",
    "    if len(bag_of_words) <= standard_size:\n",
    "        return [bag_of_words]\n",
    "    \n",
    "    slices = divide_into_slices(input_text, standard_size)\n",
    "    slices = check_slicing_criteria(slices, cosine_distance_threshold)\n",
    "    \n",
    "    return slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographical Documents:\n",
      "Document 1 (Geography):\n",
      "Geography is a systematic study of the Earth (other celestial bodies are specified, such as \"geography of Mars\", or given another name, such as areography in the case of Mars), its features, and phenomena that take place on it. For something to fall into the domain of geography, it generally needs some sort of spatial component that can be placed on a map, such as coordinates, place names, or addresses. This has led to geography being associated with cartography and place names. Although many geographers are trained in toponymy and cartology, this is not their main preoccupation. Geographers study the Earth's spatial and temporal distribution of phenomena, processes, and features as well as the interaction of humans and their environment. Because space and place affect a variety of topics, such as economics, health, climate, plants, and animals, geography is highly interdisciplinary. The interdisciplinary nature of the geographical approach depends on an attentiveness to the relationship between physical and human phenomena and their spatial patterns. Names of places...are not geography...To know by heart a whole gazetteer full of them would not, in itself, constitute anyone a geographer. Geography has higher aims than this: it seeks to classify phenomena (alike of the natural and of the political world, in so far as it treats of the latter), to compare, to generalize, to ascend from effects to causes, and, in doing so, to trace out the laws of nature and to mark their influences upon man. This is 'a description of the world'—that is Geography. In a word, Geography is a Science—a thing not of mere names but of argument and reason, of cause and effect. Geography as a discipline can be split broadly into three main branches: human geography, physical geography, and technical geography. Human geography largely focuses on the built environment and how humans create, view, manage, and influence space. Physical geography examines the natural environment and how organisms, climate, soil, water, and landforms produce and interact. The difference between these approaches led to the development of integrated geography, which combines physical and human geography and concerns the interactions between the environment and humans. Technical geography involves studying and developing the tools and techniques used by geographers, such as remote sensing, cartography, and geographic information system. Geography is a branch of inquiry that focuses on spatial information on Earth. It is an extremely broad topic and can be broken down multiple ways. There have been several approaches to doing this spanning at least several centuries, including \"four traditions of geography\" and into distinct branches. The Four traditions of geography are often used to divide the different historical approaches theories geographers have taken to the discipline. In contrast, geography's branches describe contemporary applied geographical approaches. All geographic research and analysis start with asking the question \"where,\" followed by \"why there.\" Geographers start with the fundamental assumption set forth in Tobler's first law of geography, that \"everything is related to everything else, but near things are more related than distant things.\" As spatial interrelationships are key to this synoptic science, maps are a key tool. Classical cartography has been joined by a more modern approach to geographical analysis, computer-based geographic information systems (GIS). In their study, geographers use four interrelated approaches: The concept of geography is present in all cultures, and therefore the history of the discipline is a series of competing narratives, with concepts emerging at various points across space and time. The oldest known world maps date back to ancient Babylon from the 9th century BC. The best known Babylonian world map, however, is the Imago Mundi of 600 BC. The map as reconstructed by Eckhard Unger shows Babylon on the Euphrates, surrounded by a circular landmass showing Assyria, Urartu, and several cities, in turn surrounded by a \"bitter river\" (Oceanus), with seven islands arranged around it so as to form a seven-pointed star. The accompanying text mentions seven outer regions beyond the encircling ocean. The descriptions of five of them have survived. In contrast to the Imago Mundi, an earlier Babylonian world map dating back to the 9th century BC depicted Babylon as being further north from the center of the world, though it is not certain what that center was supposed to represent. The ideas of Anaximander (c. 610–545 BC): considered by later Greek writers to be the true founder of geography, come to us through fragments quoted by his successors. Anaximander is credited with the invention of the gnomon, the simple, yet efficient Greek instrument that allowed the early measurement of latitude. Thales is also credited with the prediction of eclipses. The foundations of geography can be traced to ancient cultures, such as the ancient, medieval, and early modern Chinese. The Greeks, who were the first to explore geography as both art and science, achieved this through Cartography, Philosophy, and Literature, or through Mathematics. There is some debate about who was the first person to assert that the Earth is spherical in shape, with the credit going either to Parmenides or Pythagoras. Anaxagoras was able to demonstrate that the profile of the Earth was circular by explaining eclipses. However, he still believed that the Earth was a flat disk, as did many of his contemporaries. One of the first estimates of the radius of the Earth was made by Eratosthenes.The first rigorous system of latitude and longitude lines is credited to Hipparchus. He employed a sexagesimal system that was derived from Babylonian mathematics. The meridians were subdivided into 360°, with each degree further subdivided into 60 (minutes). To measure the longitude at different locations on Earth, he suggested using eclipses to determine the relative difference in time. The extensive mapping by the Romans as they explored new lands would later provide a high level of information for Ptolemy to construct detailed atlases. He extended the work of Hipparchus, using a grid system on his maps and adopting a length of 56.5 miles for a degree.From the 3rd century onwards, Chinese methods of geographical study and writing of geographical literature became much more comprehensive than what was found in Europe at the time (until the 13th century). Chinese geographers such as Liu An, Pei Xiu, Jia Dan, Shen Kuo, Fan Chengda, Zhou Daguan, and Xu Xiake wrote important treatises, yet by the 17th century advanced ideas and methods of Western-style geography were adopted in China.  Alexander von Humboldt (1769–1859) – published Cosmos and founder of the sub-field biogeography. Anne Kelly Knowles (Born 1957) – influential in the use of GIS and geographic methods in History. Carl O. Sauer (1889–1975) – cultural geographer. Main category: Geography Organizations  American Association of Geographers (AAG) Main category: Geography literature  Annals of the American Association of Geographers       Definition of geography at Dictionary.com Definition of geography by Lexico\n",
      "\n",
      "---\n",
      "\n",
      "Document 2 (Sea):\n",
      "The sea is the interconnected system of all the Earth's oceanic waters, including the Atlantic, Pacific, Indian, Southern and Arctic Oceans. However, the word \"sea\" can also be used for many specific, much smaller bodies of seawater, such as the North Sea or the Red Sea. There is no sharp distinction between seas and oceans, though generally seas are smaller, and are often partly (as marginal seas or particularly as a mediterranean sea) or wholly (as inland seas) enclosed by land. However, an exception to this is the Sargasso Sea which has no coastline and lies within a circular current, the North Atlantic Gyre.: 90  Seas are generally larger than lakes and contain salt water, but the Sea of Galilee is a freshwater lake. The United Nations Convention on the Law of the Sea states that all of the ocean is \"sea\". Earth is the only known planet with seas of liquid water on its surface,: 22  although Mars possesses ice caps and similar planets in other solar systems may have oceans. Earth's 1,335,000,000 cubic kilometers (320,000,000 cu mi) of sea contain about 97.2 percent of its known water and cover approximately 71 percent of its surface.: 7  Another 2.15% of Earth's water is frozen, found in the sea ice covering the Arctic Ocean, the ice cap covering Antarctica and its adjacent seas, and various glaciers and surface deposits around the world. The remainder (about 0.65% of the whole) form underground reservoirs or various stages of the water cycle, containing the freshwater encountered and used by most terrestrial life: vapor in the air, the clouds it slowly forms, the rain falling from them, and the lakes and rivers spontaneously formed as its waters flow again and again to the sea.The scientific study of water and Earth's water cycle is hydrology; hydrodynamics studies the physics of water in motion. The more recent study of the sea in particular is oceanography. This began as the study of the shape of the ocean's currents but has since expanded into a large and multidisciplinary field: it examines the properties of seawater; studies waves, tides, and currents; charts coastlines and maps the seabeds; and studies marine life. The subfield dealing with the sea's motion, its forces, and the forces acting upon it is known as physical oceanography. Marine biology (biological oceanography) studies the plants, animals, and other organisms inhabiting marine ecosystems. Both are informed by chemical oceanography, which studies the behavior of elements and molecules within the oceans: particularly, at the moment, the ocean's role in the carbon cycle and carbon dioxide's role in the increasing acidification of seawater. Marine and maritime geography charts the shape and shaping of the sea, while marine geology (geological oceanography) has provided evidence of continental drift and the composition and structure of the Earth, clarified the process of sedimentation, and assisted the study of volcanism and earthquakes. The oceans are home to a diverse collection of life forms that use it as a habitat. Since sunlight illuminates only the upper layers, the major part of the ocean exists in permanent darkness. As the different depth and temperature zones each provide habitat for a unique set of species, the marine environment as a whole encompasses an immense diversity of life. Marine habitats range from surface water to the deepest oceanic trenches, including coral reefs, kelp forests, seagrass meadows, tidepools, muddy, sandy and rocky seabeds, and the open pelagic zone. The organisms living in the sea range from whales 30 metres (98 feet) long to microscopic phytoplankton and zooplankton, fungi, and bacteria. Marine life plays an important part in the carbon cycle as photosynthetic organisms convert dissolved carbon dioxide into organic carbon and it is economically important to humans for providing fish for use as food.: 204–229 Life may have originated in the sea and all the major groups of animals are represented there. Scientists differ as to precisely where in the sea life arose: the Miller-Urey experiments suggested a dilute chemical \"soup\" in open water, but more recent suggestions include volcanic hot springs, fine-grained clay sediments, or deep-sea \"black smoker\" vents, all of which would have provided protection from damaging ultraviolet radiation which was not blocked by the early Earth's atmosphere.: 138–140  The environmental issues that affect the sea can loosely be grouped into those that stem from marine pollution, from over exploitation and those that stem from climate change. They all impact marine ecosystems and food webs and may result in consequences as yet unrecognised for the biodiversity and continuation of marine life forms. An overview of environmental issues is shown below:  Marine pollution: Pathways of pollution include direct discharge, land runoff, ship pollution, atmospheric pollution and, potentially, deep sea mining. The types of marine pollution can be grouped as pollution from marine debris, plastic pollution, including microplastics, nutrient pollution, toxins and underwater noise. Ocean surface topography – Shape of the ocean surface relative to the geoid List of seas Bay    National Oceanic and Atmospheric Administration Archived 24 April 2013 at the Wayback Machine\n",
      "\n",
      "---\n",
      "\n",
      "Document 3 (Ocean):\n",
      "  The entire ocean, containing 97% of Earth's water, spans 70.8% of Earth's surface, making it Earth's global ocean or world ocean. This makes Earth, along with its vibrant hydrosphere a \"water world\" or \"ocean world\", particularly in Earth's early history when the ocean is thought to have possibly covered Earth completely. The ocean's shape is irregular, unevenly dominating the Earth's surface. This leads to the distinction of the Earth's surface into a water and land hemisphere, as well as the division of the ocean into different oceans. Seawater covers about 361,000,000 km2 (139,000,000 sq mi) and the Ocean's furthest  pole of inaccessibility, known as \"Point Nemo\", in a region known as spacecraft cemetery of the South Pacific Ocean, at 48°52.6′S 123°23.6′W. This point is roughly 2,688 km (1,670 mi) from the nearest land.   Life within the ocean evolved 3 billion years prior to life on land. Both the depth and the distance from shore strongly influence the biodiversity of the plants and animals present in each region. The diversity of life in the ocean is immense, including:  Animals: most animal phyla have species that inhabit the ocean, including many that are found only in marine environments such as sponges, Cnidaria (such as corals and jellyfish), comb jellies, Brachiopods, and Echinoderms (such as sea urchins and sea stars). Many other familiar animal groups primarily live in the ocean, including cephalopods (includes octopus and squid), crustaceans (includes lobsters, crabs, and shrimp), fish, sharks, cetaceans (includes whales, dolphins, and porpoises). In addition, many land animals have adapted to living a major part of their life on the oceans. For instance, seabirds are a diverse group of birds that have adapted to a life mainly on the oceans. They feed on marine animals and spend most of their lifetime on water, many going on land only for breeding. Other birds that have adapted to oceans as their living space are penguins, seagulls and pelicans. Seven species of turtles, the sea turtles, also spend most of their time in the oceans. The ocean has been linked to human activity throughout history. These activities serve a wide variety of purposes, including navigation and exploration, naval warfare, travel, shipping and trade, food production (e.g. fishing, whaling, seaweed farming, aquaculture), leisure (cruising, sailing, recreational boat fishing, scuba diving), power generation (see marine energy and offshore wind power), extractive industries (offshore drilling and deep sea mining), freshwater production via desalination. Many of the world's goods are moved by ship between the world's seaports. Large quantities of goods are transported across the ocean, especially across the Atlantic and around the Pacific Rim. Many types of cargo including manufactured goods, are typically transported in standard sized, lockable containers that are loaded on purpose-built container ships at dedicated terminals. Containerization greatly boosted the efficiency and reduced the cost of shipping products by sea. This was a major factor in the rise of globalization and exponential increases in international trade in the mid-to-late 20th century.Oceans are also the major supply source for the fishing industry. Some of the major harvests are shrimp, fish, crabs, and lobster. The biggest global commercial fishery is for anchovies, Alaska pollock and tuna.: 6  A report by FAO in 2020 stated that \"in 2017, 34 percent of the fish stocks of the world's marine fisheries were classified as overfished\".: 54  Fish and other fishery products from both wild fisheries and aquaculture are among the most widely consumed sources of protein and other essential nutrients. Data in 2017 showed that \"fish consumption accounted for 17 percent of the global population's intake of animal proteins\". To fulfill this need, coastal countries have exploited marine resources in their exclusive economic zone. Fishing vessels are increasingly venturing out to exploit stocks in international waters.The ocean has a vast amount of energy carried by ocean waves, tides, salinity differences, and ocean temperature differences which can be harnessed to generate electricity. Forms of sustainable marine energy include tidal power, ocean thermal energy and wave power. Offshore wind power is captured by wind turbines placed out on the ocean; it has the advantage that wind speeds are higher than on land, though wind farms are more costly to construct offshore. There are large deposits of petroleum, as oil and natural gas, in rocks beneath the ocean floor. Offshore platforms and drilling rigs extract the oil or gas and store it for transport to land.\"Freedom of the seas\" is a principle in international law dating from the seventeenth century. It stresses freedom to navigate the oceans and disapproves of war fought in international waters. Today, this concept is enshrined in the United Nations Convention on the Law of the Sea (UNCLOS).The International Maritime Organization and the United Nations are the two major international legal organizations involved in global ocean governance. The International Maritime Organization (IMO), which was ratified in 1958, is mainly responsible for maritime safety, liability and compensation, and has held some conventions on marine pollution related to shipping incidents. Ocean governance is the conduct of the policy, actions and affairs regarding the world's oceans. Human activities affect marine life and marine habitats through many negative influences, such as marine pollution (including marine debris and microplastics) overfishing, ocean acidification and other effects of climate change on oceans. Ocean protection serves to safeguard the ecosystems in the oceans upon which humans depend. Protecting these ecosystems from threats is a major component of environmental protection. One of protective measures is the creation and enforcement of marine protected areas (MPAs). Marine protection may need to be considered within a national, regional and international context. Other measures include supply chain transparency requirement policies, policies to prevent marine pollution, ecosystem-assistance (e.g. for coral reefs) and support for sustainable seafood (e.g. sustainable fishing practices and types of aquaculture). There is also the protection of marine resources and components whose extraction or disturbance would cause substantial harm, engagement of broader publics and impacted communities, and the development of ocean clean-up projects (removal of marine plastic pollution). Examples of the latter include Clean Oceans International and The Ocean Cleanup. In 2021, 43 expert scientists published the first scientific framework version that – via integration, review, clarifications and standardization – enables the evaluation of levels of protection of marine protected areas and can serve as a guide for any subsequent efforts to improve, plan and monitor marine protection quality and extents. Examples are the efforts towards the 30%-protection-goal of the \"Global Deal For Nature\" and the UN's Sustainable Development Goal 14 (\"life below water\").In March 2023 a High Seas Treaty was signed. It is legally binding. The main achievement is the new possibility to create marine protected areas in international waters. By doing so the agreement now makes it possible to protect 30% of the oceans by 2030 (part of the 30 by 30 target). The treaty has articles regarding the principle \"polluter-pays\", and different impacts of human activities including areas beyond the national jurisdiction of the countries making those activities. The agreement was adopted by the 193 United Nations Member States. European Atlas of the Seas Land and water hemispheres List of seas   FAO (Food and Agriculture Organization of the United Nations) Fisheries Division NOAA – National Oceanic and Atmospheric Administration (United States)\n",
      "\n",
      "---\n",
      "\n",
      "Document 4 (Longitude):\n",
      "The concept of longitude was first developed by ancient Greek astronomers. Hipparchus (2nd century BCE) used a coordinate system that assumed a spherical Earth, and divided it into 360° as we still do today. His prime meridian passed through Alexandria.: 31  He also proposed a method of determining longitude by comparing the local time of a lunar eclipse at two different places, thus demonstrating an understanding of the relationship between longitude and time.: 11  Claudius Ptolemy (2nd century CE) developed a mapping system using curved parallels that reduced distortion. He also collected data for many locations, from Britain to the Middle East. He used a prime meridian through the Canary Islands, so that all longitude values would be positive. While Ptolemy's system was sound, the data he used were often poor, leading to a gross over-estimate (by about 70%) of the length of the Mediterranean.: 551–553 After the fall of the Roman Empire, interest in geography greatly declined in Europe.: 65  Hindu and Muslim astronomers continued to develop these ideas, adding many new locations and often improving on Ptolemy's data. For example al-Battānī used simultaneous observations of two lunar eclipses to determine the difference in longitude between Antakya and Raqqa with an error of less than 1°. This is considered to be the best that can be achieved with the methods then available: observation of the eclipse with the naked eye, and determination of local time using an astrolabe to measure the altitude of a suitable \"clock star\".In the later Middle Ages, interest in geography revived in the west, as travel increased, and Arab scholarship began to be known through contact with Spain and North Africa. In the 12th century, astronomical tables were prepared for a number of European cities, based on the work of al-Zarqālī in Toledo. The lunar eclipse of September 12, 1178 was used to establish the longitude differences between Toledo, Marseilles, and Hereford.: 85 Christopher Columbus made two attempts to use lunar eclipses to discover his longitude, the first in Saona Island, on 14 September 1494 (second voyage), and the second in Jamaica on 29 February 1504 (fourth voyage). It is assumed that he used astronomical tables for reference. His determinations of longitude showed large errors of 13° and 38° W respectively. Randles (1985) documents longitude measurement by the Portuguese and Spanish between 1514 and 1627 both in the Americas and Asia. Errors ranged from 2° to 25°.The telescope was invented in the early 17th century. Initially an observation device, developments over the next half century transformed it into an accurate measurement tool. The pendulum clock was patented by Christiaan Huygens in 1657 and gave an increase in accuracy of about 30 fold over previous mechanical clocks. These two inventions would revolutionise observational astronomy and cartography.On land, the period from the development of telescopes and pendulum clocks until the mid-18th century saw a steady increase in the number of places whose longitude had been determined with reasonable accuracy, often with errors of less than a degree, and nearly always within 2° to 3°. By the 1720s errors were consistently less than 1°. At sea during the same period, the situation was very different. Two problems proved intractable. The first was the need of a navigator for immediate results. The second was the marine environment. Making accurate observations in an ocean swell is much harder than on land, and pendulum clocks do not work well in these conditions. The main methods for determining longitude are listed below. With one exception (magnetic declination) they all depend on a common principle, which was to determine an absolute time from an event or measurement and to compare the corresponding local time at two different locations.  Lunar distances. In its orbit around the Earth, the Moon moves relative to the stars at a rate of just over 0.5°/hour. The angle between the Moon and a suitable star is measured with a sextant, and (after consulting tables and lengthy calculations) gives a value for absolute time. Longitude is given as an angular measurement ranging from 0° at the Prime Meridian to +180° eastward and −180° westward. The Greek letter λ (lambda) is used to denote the location of a place on Earth east or west of the Prime Meridian. Each degree of longitude is sub-divided into 60 minutes, each of which is divided into 60 seconds. A longitude is thus specified in sexagesimal notation as, for example,  23° 27′ 30″ E. For higher precision, the seconds are specified with a decimal fraction. An alternative representation uses degrees and minutes, and parts of a minute are expressed in decimal notation, thus: 23° 27.5′ E. Degrees may also be expressed as a decimal fraction: 23.45833° E. For calculations, the angular measure may be converted to radians, so longitude may also be expressed in this manner as a signed fraction of π (pi), or an unsigned fraction of 2π. For calculations, the West/East suffix is replaced by a negative sign in the western hemisphere. The international standard convention (ISO 6709)—that East is positive—is consistent with a right-handed Cartesian coordinate system, with the North Pole up. A specific longitude may then be combined with a specific latitude (positive in the northern hemisphere) to give a precise position on the Earth's surface. Confusingly, the convention of negative for East is also sometimes seen, most commonly in the United States; the Earth System Research Laboratory used it on an older version of one of their pages, in order \"to make coordinate entry less awkward\" for applications confined to the Western Hemisphere. They have since shifted to the standard approach.The longitude is singular at the Poles and calculations that are sufficiently accurate for other positions may be inaccurate at or near the Poles. Also the discontinuity at the ±180° meridian must be handled with care in calculations. An example is a calculation of east displacement by subtracting two longitudes, which gives the wrong answer if the two positions are on either side of this meridian. To avoid these complexities, some applications use another horizontal position representation. The length of a degree of longitude (east–west distance) depends only on the radius of a circle of latitude. For a sphere of radius a that radius at latitude φ is a cos φ, and the length of a one-degree (or π/180 radian) arc along a circle of latitude is       Andrews, William J. H. (1996). The Quest for Longitude. Cambridge, Massachusetts: Harvard University Press. ISBN 978-0-9644329-0-1. OCLC 59617314. Howse, Derek (1980). Greenwich Time and the Discovery of the Longitude. Philip Wilson Publishers, Ltd. ISBN 978-0-19-215948-9.  Resources for determining your latitude and longitude Archived 2008-05-19 at the Wayback Machine IAU/IAG Working Group On Cartographic Coordinates and Rotational Elements of the Planets and Satellites Archived 2006-04-06 at the Wayback Machine\n",
      "\n",
      "---\n",
      "\n",
      "Document 5 (Meteorology):\n",
      " Meteorologists are scientists who study and work in the field of meteorology. The American Meteorological Society publishes and continually updates an authoritative electronic Meteorology Glossary. Meteorologists work in government agencies, private consulting and research services, industrial enterprises, utilities, radio and television stations, and in education. In the United States, meteorologists held about 10,000 jobs in 2018.Although weather forecasts and warnings are the best known products of meteorologists for the public, weather presenters on radio and television are not necessarily professional meteorologists. They are most often reporters with little formal meteorological training, using unregulated titles such as weather specialist or weatherman. The American Meteorological Society and National Weather Association issue \"Seals of Approval\" to weather broadcasters who meet certain requirements but this is not mandatory to be hired by the media. Each science has its own unique sets of laboratory equipment. In the atmosphere, there are many things or qualities of the atmosphere that can be measured. Rain, which can be observed, or seen anywhere and anytime was one of the first atmospheric qualities measured historically. Also, two other accurately measured qualities are wind and humidity. Neither of these can be seen but can be felt. The devices to measure these three sprang up in the mid-15th century and were respectively the rain gauge, the anemometer, and the hygrometer. Many attempts had been made prior to the 15th century to construct adequate equipment to measure the many atmospheric variables. Many were faulty in some way or were simply not reliable. Even Aristotle noted this in some of his work as the difficulty to measure the air. Sets of surface measurements are important data to meteorologists. They give a snapshot of a variety of weather conditions at one single location and are usually at a weather station, a ship or a weather buoy. The measurements taken at a weather station can include any number of atmospheric observables. Usually, temperature, pressure, wind measurements, and humidity are the variables that are measured by a thermometer, barometer, anemometer, and hygrometer, respectively. Professional stations may also include air quality sensors (carbon monoxide, carbon dioxide, methane, ozone, dust, and smoke), ceilometer (cloud ceiling), falling precipitation sensor, flood sensor, lightning sensor, microphone (explosions, sonic booms, thunder), pyranometer/pyrheliometer/spectroradiometer (IR/Vis/UV photodiodes), rain gauge/snow gauge, scintillation counter (background radiation, fallout, radon), seismometer (earthquakes and tremors), transmissometer (visibility), and a GPS clock for data logging. Upper air data are of crucial importance for weather forecasting. The most widely used technique is launches of radiosondes. Supplementing the radiosondes a network of aircraft collection is organized by the World Meteorological Organization. Remote sensing, as used in meteorology, is the concept of collecting data from remote weather events and subsequently producing weather information. The common types of remote sensing are Radar, Lidar, and satellites (or photogrammetry). Each collects data about the atmosphere from a remote location and, usually, stores the data where the instrument is located. Radar and Lidar are not passive because both use EM radiation to illuminate a specific portion of the atmosphere.  Weather satellites along with more general-purpose Earth-observing satellites circling the earth at various altitudes have become an indispensable tool for studying a wide range of phenomena from forest fires to El Niño. The study of the atmosphere can be divided into distinct areas that depend on both time and spatial scales. At one extreme of this scale is climatology. In the timescales of hours to days, meteorology separates into micro-, meso-, and synoptic scale meteorology. Respectively, the geospatial size of each of these three scales relates directly with the appropriate timescale. Other subclassifications are used to describe the unique, local, or broad effects within those subclasses.     Byers, Horace. General Meteorology. New York:  McGraw-Hill, 1994. Garret, J.R. (1992) [1992]. The atmospheric boundary layer. Cambridge University Press. ISBN 978-0-521-38052-2. Glossary of Meteorology. American Meteorological Society (2nd ed.). Allen Press. 2000.{{cite book}}:  CS1 maint: others (link)  Please see weather forecasting for weather forecast sites. \n",
      "\n",
      "---\n",
      "\n",
      "Document 6 (Climate):\n",
      "Climate (from Ancient Greek  κλίμα 'inclination') is commonly defined as the weather averaged over a long period. The standard averaging period is 30 years, but other periods may be used depending on the purpose. Climate also includes statistics other than the average, such as the magnitudes of day-to-day or year-to-year variations. The Intergovernmental Panel on Climate Change (IPCC) 2001 glossary definition is as follows:  Climate in a narrow sense is usually defined as the \"average weather\", or more rigorously, as the statistical description in terms of the mean and variability of relevant quantities over a period ranging from months to thousands or millions of years. The classical period is 30 years, as defined by the World Meteorological Organization (WMO). These quantities are most often surface variables such as temperature, precipitation, and wind. Climate in a wider sense is the state, including a statistical description, of the climate system. Climate classifications are systems that categorize the world's climates. A climate classification may correlate closely with a biome classification, as climate is a major influence on life in a region. One of the most used is the Köppen climate classification scheme first developed in 1899.There are several ways to classify climates into similar regimes. Originally, climes were defined in Ancient Greece to describe the weather depending upon a location's latitude. Modern climate classification methods can be broadly divided into genetic methods, which focus on the causes of climate, and empiric methods, which focus on the effects of climate. Examples of genetic classification include methods based on the relative frequency of different air mass types or locations within synoptic weather disturbances. Examples of empiric classifications include climate zones defined by plant hardiness, evapotranspiration, or more generally the Köppen climate classification which was originally designed to identify the climates associated with certain biomes. A common shortcoming of these classification schemes is that they produce distinct boundaries between the zones they define, rather than the gradual transition of climate properties more common in nature.  Climate variability is the term to describe variations in the mean state and other characteristics of climate (such as chances or possibility of extreme weather, etc.) \"on all spatial and temporal scales beyond that of individual weather events.\" Some of the variability does not appear to be caused systematically and occurs at random times. Such variability is called random variability or noise. On the other hand, periodic variability occurs relatively regularly and in distinct modes of variability or climate patterns.There are close correlations between Earth's climate oscillations and astronomical factors (barycenter changes, solar variation, cosmic ray flux, cloud albedo feedback, Milankovic cycles), and modes of heat distribution between the ocean-atmosphere climate system. In some cases, current, historical and paleoclimatological natural oscillations may be masked by significant volcanic eruptions, impact events, irregularities in climate proxy data, positive feedback processes or anthropogenic emissions of substances such as greenhouse gases.Over the years, the definitions of climate variability and the related term climate change have shifted. While the term climate change now implies change that is both long-term and of human causation, in the 1960s the word climate change was used for what we now describe as climate variability, that is, climatic inconsistencies and anomalies. Climate change is the variation in global or regional climates over time. It reflects changes in the variability or average state of the atmosphere over time scales ranging from decades to millions of years. These changes can be caused by processes internal to the Earth, external forces (e.g. variations in sunlight intensity) or, more recently, human activities.  Scientists have identified Earth's Energy Imbalance (EEI) to be a fundamental metric of the status of global change.In recent usage, especially in the context of environmental policy, the term \"climate change\" often refers only to changes in modern climate, including the rise in average surface temperature known as global warming. In some cases, the term is also used with a presumption of human causation, as in the United Nations Framework Convention on Climate Change (UNFCCC). The UNFCCC uses \"climate variability\" for non-human caused variations.Earth has undergone periodic climate shifts in the past, including four major ice ages. These consist of glacial periods where conditions are colder than normal, separated by interglacial periods. The accumulation of snow and ice during a glacial period increases the surface albedo, reflecting more of the Sun's energy into space and maintaining a lower atmospheric temperature. Increases in greenhouse gases, such as by volcanic activity, can increase the global temperature and produce an interglacial period. Suggested causes of ice age periods include the positions of the continents, variations in the Earth's orbit, changes in the solar output, and volcanism. However, these naturally-caused changes in climate occur on a much slower time scale than the present rate of change which is caused by the emission of greenhouse gases by human activities. Climate models use quantitative methods to simulate the interactions and transfer of radiative energy between the atmosphere, oceans, land surface and ice through a series of physics equations. They are used for a variety of purposes; from the study of the dynamics of the weather and climate system, to projections of future climate. All climate models balance, or very nearly balance, incoming energy as short wave (including visible) electromagnetic radiation to the Earth with outgoing energy as long wave (infrared) electromagnetic radiation from the earth. Any imbalance results in a change in the average temperature of the earth. Climate models are available on different resolutions ranging from >100 km to 1 km. High resolutions in global climate models require significant computational resources, and so only a few global datasets exist. Global climate models can be dynamically or statistically downscaled to regional climate models to analyze impacts of climate change on a local scale. Examples are ICON or mechanistically downscaled data such as CHELSA (Climatologies at high resolution for the earth's land surface areas).The most talked-about applications of these models in recent years have been their use to infer the consequences of increasing greenhouse gases in the atmosphere, primarily carbon dioxide (see greenhouse gas). These models predict an upward trend in the global mean surface temperature, with the most rapid increase in temperature being projected for the higher latitudes of the Northern Hemisphere. Models can range from relatively simple to quite complex. Simple radiant heat transfer models treat the earth as a single point and average outgoing energy. This can be expanded vertically (as in radiative-convective models), or horizontally. Finally, more complex (coupled) atmosphere–ocean–sea ice global climate models discretise and solve the full equations for mass and energy transfer and radiant exchange.   Buchan, Alexander (1878). \"Climate\" . Encyclopædia Britannica. Vol. VI (9th ed.). pp. 1–7. Reumert, Johannes: \"Vahls climatic divisions. An explanation\" (Geografisk Tidsskrift, Band 48; 1946) The Study of Climate on Alien Worlds; Characterizing atmospheres beyond our Solar System is now within our reach Kevin Heng July–August 2012 American Scientist  NOAA Climate Services Portal NOAA State of the Climate\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Non-Geographical Documents:\n",
      "Document 1 (Artificial intelligence):\n",
      "The general problem of simulating (or creating) intelligence has been broken into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research. AI research uses a wide variety of techniques to accomplish the goals above. AI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's Face ID or Microsoft's DeepFace and Google's FaceNet) and image labeling (used by Facebook, Apple's iPhoto and TikTok). AI, like any powerful technology, has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of Deep Mind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified.Anyone looking to use machine learning as part of real-world, in-production systems needs to factor ethics into their AI training processes and strive to avoid bias. This is especially true when using AI algorithms that are inherently unexplainable in deep learning. The study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate both mathematical deduction and formal reasoning, which is known as the Church–Turing thesis. This, along with concurrent discoveries in cybernetics and information theory, led researchers to consider the possibility of building an \"electronic brain\".Alan Turing was thinking about machine intelligence at least as early as 1941, when he circulated a paper on machine intelligence which could be the earliest paper in the field of AI – though it is now lost. The first available paper generally recognized as \"AI\" was McCullouch and Pitts design for Turing-complete \"artificial neurons\" in 1943 – the first mathematical model of a neural network. The paper was influenced by Turing's earlier paper 'On Computable Numbers' from 1936 using similar two-state boolean 'neurons', but was the first to apply it to neuronal function.The term 'Machine Intelligence' was used by Alan Turing during his life which was later often referred to as 'Artificial Intelligence' after his death in 1954. In 1950 Turing published the best known of his papers 'Computing Machinery and Intelligence', the paper introduced his concept of what is now known as the Turing test to the general public. Then followed three radio broadcasts on AI by Turing, the lectures: 'Intelligent Machinery, A Heretical Theory’, ‘Can Digital Computers Think’? and the panel discussion ‘Can Automatic Calculating Machines be Said to Think’. By 1956 computer intelligence had been actively pursued for more than a decade in Britain; the earliest AI programmes were written there in 1951–1952.In 1951, using a Ferranti Mark 1 computer of the University of Manchester, checkers and chess programs were wrote where you could play against the computer. The field of American AI research was founded at a workshop at Dartmouth College in 1956. The attendees became the leaders of AI research in the 1960s. They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial Intelligence laboratories were set up at a number of British and US Universities in the latter 1950s and early 1960s.They had, however, underestimated the difficulty of the problem. Both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill and ongoing pressure from the U.S. Congress to fund more productive projects. Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether. The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.In the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.Many researchers began to doubt that the current practices would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into \"sub-symbolic\" approaches. Robotics researchers, such as Rodney Brooks, rejected \"representation\" in general and focussed directly on engineering machines that move and survive. Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic. But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others. In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics). By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\".Several academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field. For many specific tasks, other methods were abandoned.   Thought-capable artificial beings have appeared as storytelling devices since antiquity, and have been a persistent theme in science fiction.A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the \"Multivac\" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics; while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence. AI effect Artificial intelligence detection software – Software to detect AI-generated contentPages displaying short descriptions of redirect targets Artificial intelligence in healthcare – Overview of the use of artificial intelligence in healthcare     \"Artificial Intelligence\". Internet Encyclopedia of Philosophy. Thomason, Richmond. \"Logic and Artificial Intelligence\". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.\n",
      "\n",
      "---\n",
      "\n",
      "Document 2 (Computer Science):\n",
      "The earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.Wilhelm Schickard designed and constructed the first working mechanical calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner. Leibniz may be considered the first computer scientist and information theorist, because of various reasons, including the fact that he documented the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first automatic mechanical calculator, his Difference Engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his Analytical Engine. He started developing this machine in 1834, and \"in less than two years, he had sketched out many of the salient features of the modern computer\". \"A crucial step was the adoption of a punched card system derived from the Jacquard loom\" making it infinitely programmable. In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909 published the 2nd of the only two designs for mechanical analytical engines in history. In 1914, the Spanish engineer Leonardo Torres Quevedo published his Essays on Automatics, and designed, inspired by Babbage, a theoretical electromechanical calculating machine which was to be controlled by a read-only program. The paper also introduced the idea of floating-point arithmetic. In 1920, to celebrate the 100th anniversary of the invention of the arithmometer, Torres presented in Paris the Electromechanical Arithmometer, a prototype that demonstrated the feasibility of an electromechanical analytical engine, on which commands could be typed and the results printed automatically. In 1937, one hundred years after Babbage's impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as \"Babbage's dream come true\". During the 1940s, with the development of new and more powerful computing machines such as the Atanasoff–Berry computer and ENIAC, the term computer came to refer to the machines rather than their human predecessors. As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. In 1945, IBM founded the Watson Scientific Computing Laboratory at Columbia University in New York City. The renovated fraternity house on Manhattan's West Side was IBM's first laboratory devoted to pure science. The lab is the forerunner of IBM's Research Division, which today operates research facilities around the world. Ultimately, the close relationship between IBM and Columbia University was instrumental in the emergence of a new scientific discipline, with Columbia offering one of the first academic-credit courses in computer science in 1946. Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. The world's first computer science degree program, the Cambridge Diploma in Computer Science, began at the University of Cambridge Computer Laboratory in 1953. The first computer science department in the United States was formed at Purdue University in 1962. Since practical computers became available, many applications of computing have become distinct areas of study in their own rights. Although first proposed in 1956, the term \"computer science\" appears in a 1959 article in Communications of the ACM, in which Louis Fein argues for the creation of a Graduate School in Computer Sciences analogous to the creation of Harvard Business School in 1921. Louis justifies the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline. His efforts, and those of others such as numerical analyst George Forsythe, were rewarded: universities went on to create such departments, starting with Purdue in 1962. Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed. Certain departments of major universities prefer the term computing science, to emphasize precisely that difference. Danish scientist Peter Naur suggested the term datalogy, to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.  As a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.CSAB, formerly called Computing Sciences Accreditation Board—which is made up of representatives of the Association for Computing Machinery (ACM), and the IEEE Computer Society (IEEE CS)—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science. The philosopher of computing Bill Rapaport noted three Great Insights of Computer Science: Gottfried Wilhelm Leibniz's, George Boole's, Alan Turing's, Claude Shannon's, and Samuel Morse's insight: there are only two objects that a computer has to deal with in order to represent \"anything\".All the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as \"on/off\", \"magnetized/de-magnetized\", \"high-voltage/low-voltage\", etc.). Alan Turing's insight: there are only five actions that a computer has to perform in order to do \"anything\".Every algorithm can be expressed in a language for a computer consisting of only five basic instructions:move left one location; Programming languages can be used to accomplish different tasks in different ways. Common programming paradigms include:  Functional programming, a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements. Conferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals. Computer Science, known by its near synonyms, Computing, Computer Studies, has been taught in UK schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students. In 1981, the BBC produced a micro-computer and classroom network and Computer Studies became common for GCE O level students (11–16-year-old), and Computer Science to A level students. Its importance was recognised, and it became a compulsory part of the National Curriculum, for Key Stage 3 & 4. In September 2014 it became an entitlement for all pupils over the age of 4.In the US, with 14,000 school districts deciding the curriculum, provision was fractured. According to a 2010 report by the Association for Computing Machinery (ACM) and Computer Science Teachers Association (CSTA), only 14 out of 50 states have adopted significant education standards for high school computer science. According to a 2021 report, only 51% of high schools in the US offer computer science.Israel, New Zealand, and South Korea have included computer science in their national secondary education curricula, and several others are following.      DBLP Computer Science Bibliography Association for Computing Machinery\n",
      "\n",
      "---\n",
      "\n",
      "Document 3 (Medical):\n",
      "Medicine (UK:  , US:  ) is the science and practice of the diagnosis, prognosis, treatment, and prevention of disease. The word \"medicine\" is derived from Latin medicus, meaning \"a physician\". Medical availability and clinical practice vary across the world due to regional differences in culture and technology. Modern scientific medicine is highly developed in the Western world, while in developing countries such as parts of Africa or Asia, the population may rely more heavily on traditional medicine with limited evidence and efficacy and no required formal training for practitioners.In the developed world, evidence-based medicine is not universally used in clinical practice; for example, a 2007 survey of literature reviews found that about 49% of the interventions lacked sufficient evidence to support either benefit or harm.In modern clinical practice, physicians and physician assistants personally assess patients to diagnose, prognose, treat, and prevent disease using clinical judgment. The doctor-patient relationship typically begins with an interaction with an examination of the patient's medical history and medical record, followed by a medical interview and a physical examination. Basic diagnostic medical devices (e.g., stethoscope, tongue depressor) are typically used. After examining for signs and interviewing for symptoms, the doctor may order medical tests (e.g., blood tests), take a biopsy, or prescribe pharmaceutical drugs or other therapies. Differential diagnosis methods help to rule out conditions based on the information provided. During the encounter, properly informing the patient of all relevant facts is an important part of the relationship and the development of trust. The medical encounter is then documented in the medical record, which is a legal document in many jurisdictions. Follow-ups may be shorter but follow the same general procedure, and specialists follow a similar process. The diagnosis and treatment may take only a few minutes or a few weeks, depending on the complexity of the issue. The components of the medical interview and encounter are:  Contemporary medicine is, in general, conducted within health care systems. Legal, credentialing, and financing frameworks are established by individual governments, augmented on occasion by international organizations, such as churches. The characteristics of any given health care system have a significant impact on the way medical care is provided. From ancient times, Christian emphasis on practical charity gave rise to the development of systematic nursing and hospitals, and the Catholic Church today remains the largest non-government provider of medical services in the world. Advanced industrial countries (with the exception of the United States) and many developing countries provide medical services through a system of universal health care that aims to guarantee care for all through a single-payer health care system or compulsory private or cooperative health insurance. This is intended to ensure that the entire population has access to medical care on the basis of need rather than ability to pay. Delivery may be via private medical practices, state-owned hospitals and clinics, or charities, most commonly a combination of all three. Most tribal societies provide no guarantee of healthcare for the population as a whole. In such societies, healthcare is available to those who can afford to pay for it, have self-insured it (either directly or as part of an employment contract), or may be covered by care financed directly by the government or tribe. Working together as an interdisciplinary team, many highly trained health professionals besides medical practitioners are involved in the delivery of modern health care. Examples include: nurses, emergency medical technicians and paramedics, laboratory scientists, pharmacists, podiatrists, physiotherapists, respiratory therapists, speech therapists, occupational therapists, radiographers, dietitians, and bioengineers, medical physicists, surgeons, surgeon's assistant, surgical technologist. The scope and sciences underpinning human medicine overlap many other fields. A patient admitted to the hospital is usually under the care of a specific team based on their main presenting problem, e.g., the cardiology team, who then may interact with other specialties, e.g., surgical, radiology, to help diagnose or treat the main problem or any subsequent complications/developments. Physicians have many specializations and subspecializations into certain branches of medicine, which are listed below. There are variations from country to country regarding which specialties certain subspecialties are in. Medical education and training varies around the world. It typically involves entry level education at a university medical school, followed by a period of supervised practice or internship, or residency. This can be followed by postgraduate vocational training. A variety of teaching methods have been employed in medical education, still itself a focus of active research. In Canada and the United States of America, a Doctor of Medicine degree, often abbreviated M.D., or a Doctor of Osteopathic Medicine degree, often abbreviated as D.O. and unique to the United States, must be completed in and delivered from a recognized university. Since knowledge, techniques, and medical technology continue to evolve at a rapid rate, many regulatory authorities require continuing medical education. Medical practitioners upgrade their knowledge in various ways, including medical journals, seminars, conferences, and online programs.  A database of objectives covering medical knowledge, as suggested by national societies across the United States, can be searched at http://data.medobjectives.marian.edu/ Archived 4 October 2018 at the Wayback Machine. In most countries, it is a legal requirement for a medical doctor to be licensed or registered. In general, this entails a medical degree from a university and accreditation by a medical board or an equivalent national organization, which may ask the applicant to pass exams. This restricts the considerable legal authority of the medical profession to physicians that are trained and qualified by national standards. It is also intended as an assurance to patients and as a safeguard against charlatans that practice inadequate medicine for personal gain. While the laws generally require medical doctors to be trained in \"evidence based\", Western, or Hippocratic Medicine, they are not intended to discourage different paradigms of health. Medical ethics is a system of moral principles that apply values and judgments to the practice of medicine. As a scholarly discipline, medical ethics encompasses its practical application in clinical settings as well as work on its history, philosophy, theology, and sociology. Six of the values that commonly apply to medical ethics discussions are:  autonomy – the patient has the right to refuse or choose their treatment. (Latin: Voluntas aegroti suprema lex.)  Evidence-based medicine, prevention of medical error (and other \"iatrogenesis\"), and avoidance of unnecessary health care are a priority in modern medical systems. These topics generate significant political and public policy attention, particularly in the United States where healthcare is regarded as excessively costly but population health metrics lag similar nations.Globally, many developing countries lack access to care and access to medicines. As of 2015, most wealthy developed countries provide health care to all citizens, with a few exceptions such as the United States where lack of health insurance coverage may limit access.   == References ==\n",
      "\n",
      "---\n",
      "\n",
      "Document 4 (History):\n",
      "The word history comes from historía (Ancient Greek: ἱστορία, romanized: historíā, lit. 'inquiry, knowledge from inquiry, or judge'). It was in that sense that Aristotle used the word in his History of Animals. The ancestor word ἵστωρ is attested early on in Homeric Hymns, Heraclitus, the Athenian ephebes' oath, and in Boeotic inscriptions (in a legal sense, either \"judge\" or \"witness\", or similar). The Greek word was borrowed into Classical Latin as historia, meaning \"investigation, inquiry, research, account, description, written account of past events, writing of history, historical narrative, recorded knowledge of past events, story, narrative\". History was borrowed from Latin (possibly via Old Irish or Old Welsh) into Old English as stær (\"history, narrative, story\"), but this word fell out of use in the late Old English period. Meanwhile, as Latin became Old French (and Anglo-Norman), historia developed into forms such as istorie, estoire, and historie, with new developments in the meaning: \"account of the events of a person's life (beginning of the 12th century), chronicle, account of events as relevant to a group of people or people in general (1155), dramatic or pictorial representation of historical events (c. 1240), body of knowledge relative to human evolution, science (c. 1265), narrative of real or imaginary events, story (c. 1462)\".It was from Anglo-Norman that history was brought into Middle English, and it has persisted. It appears in the 13th-century Ancrene Wisse, but seems to have become a common word in the late 14th century, with an early attestation appearing in John Gower's Confessio Amantis of the 1390s (VI.1383): \"I finde in a bok compiled | To this matiere an old histoire, | The which comth nou to mi memoire\". In Middle English, the meaning of history was \"story\" in general. The restriction to the meaning \"the branch of knowledge that deals with past events; the formal record or study of past events, esp. human affairs\" arose in the mid-15th century. With the Renaissance, older senses of the word were revived, and it was in the Greek sense that Francis Bacon used the term in the late 16th century, when he wrote about natural history. For him, historia was \"the knowledge of objects determined by space and time\", that sort of knowledge provided by memory (while science was provided by reason, and poetry was provided by fantasy).In an expression of the linguistic synthetic vs. analytic/isolating dichotomy, English like Chinese (史 vs. 诌) now designates separate words for human history and storytelling in general. In modern German, French, and most Germanic and Romance languages, which are solidly synthetic and highly inflected, the same word is still used to mean both \"history\" and \"story\". Historian in the sense of a \"researcher of history\" is attested from 1531. In all European languages, the substantive history is still used to mean both \"what happened with men\", and \"the scholarly study of the happened\", the latter sense sometimes distinguished with a capital letter, or the word historiography. The adjective historical is attested from 1661, and historic from 1669. Historians write in the context of their own time, and with due regard to the current dominant ideas of how to interpret the past, and sometimes write to provide lessons for their own society. In the words of Benedetto Croce, \"All history is contemporary history\". History is facilitated by the formation of a \"true discourse of past\" through the production of narrative and analysis of past events relating to the human race. The modern discipline of history is dedicated to the institutional production of this discourse. All events that are remembered and preserved in some authentic form constitute the historical record. The task of historical discourse is to identify the sources which can most usefully contribute to the production of accurate accounts of past. Therefore, the constitution of the historian's archive is a result of circumscribing a more general archive by invalidating the usage of certain texts and documents (by falsifying their claims to represent the \"true past\"). Part of the historian's role is to skillfully and objectively use the many sources from the past, most often found in the archives. The process of creating a narrative inevitably generates debate, as historians remember or emphasize different events of the past.The study of history has sometimes been classified as part of the humanities, other times part of the social sciences. It can be seen as a bridge between those two broad areas, incorporating methodologies from both. Some historians strongly support one or the other classification. In the 20th century the Annales school revolutionized the study of history, by using such outside disciplines as economics, sociology, and geography in the study of global history.Traditionally, historians have recorded events of the past, either in writing or by passing on an oral tradition, and attempted to answer historical questions through the study of written documents and oral accounts. From the beginning, historians have used such sources as monuments, inscriptions, and pictures. In general, the sources of historical knowledge can be separated into three categories: what is written, what is said, and what is physically preserved, and historians often consult all three. But writing is the marker that separates history from what comes before. Archaeology is especially helpful in unearthing buried sites and objects, which contribute to the study of history. Archeological finds rarely stand alone, with narrative sources complementing its discoveries. Archeology's methodologies and approaches are independent from the field of history. \"Historical archaeology\" is a specific branch of archeology which often contrasts its conclusions against those of contemporary textual sources. For example, Mark Leone, the excavator and interpreter of historical Annapolis, Maryland, US, has sought to understand the contradiction between textual documents idealizing \"liberty\" and the material record, demonstrating the possession of slaves and the inequalities of wealth made apparent by the study of the total historical environment. Human history is the memory of the past experience of Homo sapiens sapiens around the world, as that experience has been preserved, largely in written records. By \"prehistory\", historians mean the recovery of knowledge of the past in an area where no written records exist, or where the writing of a culture is not understood. By studying painting, drawings, carvings, and other artifacts, some information can be recovered even in the absence of a written record. Since the 20th century, the study of prehistory is considered essential to avoid history's implicit exclusion of certain civilizations, such as those of sub-Saharan Africa and pre-Columbian America. Historians in the West have been criticized for focusing disproportionately on the Western world. In 1961, British historian E. H. Carr wrote:  The line of demarcation between prehistoric and historical times is crossed when people cease to live only in the present, and become consciously interested both in their past and in their future. History begins with the handing down of tradition; and tradition means the carrying of the habits and lessons of the past into the future. Records of the past begin to be kept for the benefit of future generations. Historiography has a number of related meanings. Firstly, it can refer to how history has been produced: the story of the development of methodology and practices (for example, the move from short-term biographical narrative toward long-term thematic analysis). Secondly, it can refer to what has been produced: a specific body of historical writing (for example, \"medieval historiography during the 1960s\" means \"Works of medieval history written during the 1960s\"). Thirdly, it may refer to why history is produced: the philosophy of history. As a meta-level analysis of descriptions of the past, this third conception can relate to the first two in that the analysis usually focuses on the narratives, interpretations, world view, use of evidence, or method of presentation of other historians. Historians debate whether history can be taught as a single coherent narrative or a series of competing narratives. Europeans have written and published extensively to pull together a \"universal history\" in the early modern period. This written corpus and discourse in Europe includes ethnographic encounters, comparative philosophy, as well as archaeological discovery.Herodotus, from the 5th-century BC, has been acclaimed as the \"father of history\". However, his contemporary Thucydides is credited with having first approached history with a well-developed historical method in the History of the Peloponnesian War. Thucydides, unlike Herodotus, regarded history as the product of the choices and actions of humans, and looked at cause and effect, rather than the result of divine intervention (though Herodotus was not wholly committed to this idea himself). In his historical method, Thucydides emphasized chronology, a nominally neutral point of view, and that the human world was the result of human actions. Greek historians viewed history as cyclical, with events regularly recurring.There was sophisticated use of historical method in ancient and medieval China. The groundwork for professional historiography in East Asia was established by court historian Sima Qian (145–90 BC), author of the Records of the Grand Historian (Shiji) and posthumously known as the Father of Chinese historiography. Saint Augustine was influential in Christian and Western thought at the beginning of the medieval period. Through the Medieval and Renaissance periods, history was often studied through a sacred or religious perspective. Around 1800, German philosopher and historian Georg Wilhelm Friedrich Hegel brought philosophy and a more secular approach in historical study.In the preface to his book, the Muqaddimah (1377), the Arab historian and early sociologist, Ibn Khaldun, warned of 7 mistakes he thought historians committed. In this criticism, he approached the past as strange and in need of interpretation. The originality of Ibn Khaldun was to claim that the cultural difference of another age must govern the evaluation of relevant historical material, to distinguish the principles according to which it might be possible to attempt the evaluation, and to feel the need for experience, in addition to rational principles, in order to assess a culture of the past. Ibn Khaldun criticized \"idle superstition and uncritical acceptance of historical data\". He introduced a scientific method to the study of history, and referred to it as his \"new science\". His method laid the groundwork for the observation of the role of state, communication, propaganda and systematic bias in history, and so is considered to be the \"father of historiography\" or the \"father of the philosophy of history\".In the West, historians developed modern methods of historiography in the 17th and 18th centuries, especially in France and Germany. In 1851, Herbert Spencer summarized these methods:\"From the successive strata of our historical deposits, they [historians] diligently gather all the highly colored fragments, pounce upon everything that is curious and sparkling and chuckle like children over their glittering acquisitions; meanwhile the rich veins of wisdom that ramify amidst this worthless debris, lie utterly neglected. Cumbrous volumes of rubbish are greedily accumulated, while those masses of rich ore, that should have been dug out, and from which golden truths might have been smelted, are left untaught and unsought.\" By the \"rich ore\" Spencer meant scientific theory of history. Meanwhile, Henry Thomas Buckle expressed a dream of history becoming one day a science: \"In regard to nature, events apparently the most irregular and capricious have been explained and have been shown to be in accordance with certain fixed and universal laws. This has been done because men of ability and, above all, men of patient, untiring thought have studied events with the view of discovering their regularity, and if human events were subject to a similar treatment, we have every right to expect similar results. Contrary to Buckle's dream, the 19th-century historian with greatest influence on methods became Leopold von Ranke in Germany. He limited history to \"what really happened\" and by this directed the field further away from science. For Ranke, historical data should be collected carefully, examined objectively and put together with critical rigor. But these procedures \"are merely the prerequisites and preliminaries of science. The heart of science is searching out order and regularity in the data being examined and in formulating generalizations or laws about them.\"  Professional and amateur historians discover, collect, organize, and present information about past events. They discover this information through archeological evidence, written primary sources, verbal stories or oral histories, and other archival material. In lists of historians, historians can be grouped by order of the historical period in which they were writing, which is not necessarily the same as the period in which they specialized. Chroniclers and annalists, though they are not historians in the true sense, are also frequently included. Since the 20th century, Western historians have disavowed the aspiration to provide the \"judgement of history\". The goals of historical judgements or interpretations are separate to those of legal judgements, that need to be formulated quickly after the events and be final. A related issue to that of the judgement of history is that of collective memory. Pseudohistory is a term applied to texts which purport to be historical in nature but which depart from standard historiographical conventions in a way which undermines their conclusions. It is closely related to deceptive historical revisionism. Works which draw controversial conclusions from new, speculative, or disputed historical evidence, particularly in the fields of national, political, military, and religious affairs, are often rejected as pseudohistory.  Glossary of history Outline of history   Official website of BestHistorySites Official website of BBC History Internet History Sourcebooks Project See also Internet History Sourcebooks Project (Collections of public domain and copy-permitted historical texts for educational use)\n",
      "\n",
      "---\n",
      "\n",
      "Input Text (Geographical):\n",
      "Geography is a systematic study of the Earth (other celestial bodies are specified, such as \"geography of Mars\", or given another name, such as areography in the case of Mars), its features, and phenomena that take place on it. For something to fall into the domain of geography, it generally needs some sort of spatial component that can be placed on a map, such as coordinates, place names, or addresses. This has led to geography being associated with cartography and place names. Although many geographers are trained in toponymy and cartology, this is not their main preoccupation. Geographers study the Earth's spatial and temporal distribution of phenomena, processes, and features as well as the interaction of humans and their environment. Because space and place affect a variety of topics, such as economics, health, climate, plants, and animals, geography is highly interdisciplinary. The interdisciplinary nature of the geographical approach depends on an attentiveness to the relationship between physical and human phenomena and their spatial patterns. Names of places...are not geography...To know by heart a whole gazetteer full of them would not, in itself, constitute anyone a geographer. Geography has higher aims than this: it seeks to classify phenomena (alike of the natural and of the political world, in so far as it treats of the latter), to compare, to generalize, to ascend from effects to causes, and, in doing so, to trace out the laws of nature and to mark their influences upon man. This is 'a description of the world'—that is Geography. In a word, Geography is a Science—a thing not of mere names but of argument and reason, of cause and effect. Geography as a discipline can be split broadly into three main branches: human geography, physical geography, and technical geography. Human geography largely focuses on the built environment and how humans create, view, manage, and influence space. Physical geography examines the natural environment and how organisms, climate, soil, water, and landforms produce and interact. The difference between these approaches led to the development of integrated geography, which combines physical and human geography and concerns the interactions between the environment and humans. Technical geography involves studying and developing the tools and techniques used by geographers, such as remote sensing, cartography, and geographic information system. Geography is a branch of inquiry that focuses on spatial information on Earth. It is an extremely broad topic and can be broken down multiple ways. There have been several approaches to doing this spanning at least several centuries, including \"four traditions of geography\" and into distinct branches. The Four traditions of geography are often used to divide the different historical approaches theories geographers have taken to the discipline. In contrast, geography's branches describe contemporary applied geographical approaches. All geographic research and analysis start with asking the question \"where,\" followed by \"why there.\" Geographers start with the fundamental assumption set forth in Tobler's first law of geography, that \"everything is related to everything else, but near things are more related than distant things.\" As spatial interrelationships are key to this synoptic science, maps are a key tool. Classical cartography has been joined by a more modern approach to geographical analysis, computer-based geographic information systems (GIS). In their study, geographers use four interrelated approaches: The concept of geography is present in all cultures, and therefore the history of the discipline is a series of competing narratives, with concepts emerging at various points across space and time. The oldest known world maps date back to ancient Babylon from the 9th century BC. The best known Babylonian world map, however, is the Imago Mundi of 600 BC. The map as reconstructed by Eckhard Unger shows Babylon on the Euphrates, surrounded by a circular landmass showing Assyria, Urartu, and several cities, in turn surrounded by a \"bitter river\" (Oceanus), with seven islands arranged around it so as to form a seven-pointed star. The accompanying text mentions seven outer regions beyond the encircling ocean. The descriptions of five of them have survived. In contrast to the Imago Mundi, an earlier Babylonian world map dating back to the 9th century BC depicted Babylon as being further north from the center of the world, though it is not certain what that center was supposed to represent. The ideas of Anaximander (c. 610–545 BC): considered by later Greek writers to be the true founder of geography, come to us through fragments quoted by his successors. Anaximander is credited with the invention of the gnomon, the simple, yet efficient Greek instrument that allowed the early measurement of latitude. Thales is also credited with the prediction of eclipses. The foundations of geography can be traced to ancient cultures, such as the ancient, medieval, and early modern Chinese. The Greeks, who were the first to explore geography as both art and science, achieved this through Cartography, Philosophy, and Literature, or through Mathematics. There is some debate about who was the first person to assert that the Earth is spherical in shape, with the credit going either to Parmenides or Pythagoras. Anaxagoras was able to demonstrate that the profile of the Earth was circular by explaining eclipses. However, he still believed that the Earth was a flat disk, as did many of his contemporaries. One of the first estimates of the radius of the Earth was made by Eratosthenes.The first rigorous system of latitude and longitude lines is credited to Hipparchus. He employed a sexagesimal system that was derived from Babylonian mathematics. The meridians were subdivided into 360°, with each degree further subdivided into 60 (minutes). To measure the longitude at different locations on Earth, he suggested using eclipses to determine the relative difference in time. The extensive mapping by the Romans as they explored new lands would later provide a high level of information for Ptolemy to construct detailed atlases. He extended the work of Hipparchus, using a grid system on his maps and adopting a length of 56.5 miles for a degree.From the 3rd century onwards, Chinese methods of geographical study and writing of geographical literature became much more comprehensive than what was found in Europe at the time (until the 13th century). Chinese geographers such as Liu An, Pei Xiu, Jia Dan, Shen Kuo, Fan Chengda, Zhou Daguan, and Xu Xiake wrote important treatises, yet by the 17th century advanced ideas and methods of Western-style geography were adopted in China.  Alexander von Humboldt (1769–1859) – published Cosmos and founder of the sub-field biogeography. Anne Kelly Knowles (Born 1957) – influential in the use of GIS and geographic methods in History. Carl O. Sauer (1889–1975) – cultural geographer. Main category: Geography Organizations  American Association of Geographers (AAG) Main category: Geography literature  Annals of the American Association of Geographers       Definition of geography at Dictionary.com Definition of geography by Lexico\n",
      "\n",
      "Resulting Slices:\n",
      "Slice 1: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 2 3 1 1\n",
      " 1 1 1 1 7 1 1 1 1 1 1 1 1 3 1 1 1 1 3 3 2 1 4 1 1 1 1 1 1 1 1 4 1 1 1 1 1\n",
      " 4 1 1 2 2 1 2 6 1 1 1 3 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1]\n",
      "Slice 2: [ 1  1  1  2  2  1  1  1  4  3  1  1  2  1  2  1  1  1  1  1  1  1  2  1\n",
      "  1  2  1  4  3  1  1  1  1  1  1  2  1  8  1  3  1  2  1  1  1  1  1  1\n",
      "  4  1  1  1  1  2  1  1  2  1  1  1  1  1  1  2  1  5  1  1  2  1  1  1\n",
      "  1  1  2  3  1  1  1  1  1  2 20 32  2  1  1  1  3  1  1  1  1  1  1  2\n",
      "  1  2  2  7  1]\n",
      "Slice 3: [2 2 1 1 2 1 4 1 1 1 3 2 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1\n",
      " 1 1 3 1 1 2 1 4 1 1 2 8 2 1 2 2 1 1 1 1 3 1 1 2 1 1 2 5 1 4 1 1 1 1 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 4 1 4 6 1 2 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Slice 4: [1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 3 3 1 1 1 2 1 1 1 1 3 1 5 1 1 1\n",
      " 1 2 1 5 1 1 2 1 1 1 2 1 1 5 1 1 1 2 1 1 1 1 1 1 1 1 3 1 1 3 1 2 2 1 2 2 1\n",
      " 1 1 1 1 1 1 1 1 6 1 1 1 1 1 1 1 1 1 1 1 6 2 1 1 1 1 1]\n",
      "Slice 5: [1 2 1]\n",
      "Input Text (Non-Geographical):\n",
      "The general problem of simulating (or creating) intelligence has been broken into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research. AI research uses a wide variety of techniques to accomplish the goals above. AI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's Face ID or Microsoft's DeepFace and Google's FaceNet) and image labeling (used by Facebook, Apple's iPhoto and TikTok). AI, like any powerful technology, has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of Deep Mind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified.Anyone looking to use machine learning as part of real-world, in-production systems needs to factor ethics into their AI training processes and strive to avoid bias. This is especially true when using AI algorithms that are inherently unexplainable in deep learning. The study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate both mathematical deduction and formal reasoning, which is known as the Church–Turing thesis. This, along with concurrent discoveries in cybernetics and information theory, led researchers to consider the possibility of building an \"electronic brain\".Alan Turing was thinking about machine intelligence at least as early as 1941, when he circulated a paper on machine intelligence which could be the earliest paper in the field of AI – though it is now lost. The first available paper generally recognized as \"AI\" was McCullouch and Pitts design for Turing-complete \"artificial neurons\" in 1943 – the first mathematical model of a neural network. The paper was influenced by Turing's earlier paper 'On Computable Numbers' from 1936 using similar two-state boolean 'neurons', but was the first to apply it to neuronal function.The term 'Machine Intelligence' was used by Alan Turing during his life which was later often referred to as 'Artificial Intelligence' after his death in 1954. In 1950 Turing published the best known of his papers 'Computing Machinery and Intelligence', the paper introduced his concept of what is now known as the Turing test to the general public. Then followed three radio broadcasts on AI by Turing, the lectures: 'Intelligent Machinery, A Heretical Theory’, ‘Can Digital Computers Think’? and the panel discussion ‘Can Automatic Calculating Machines be Said to Think’. By 1956 computer intelligence had been actively pursued for more than a decade in Britain; the earliest AI programmes were written there in 1951–1952.In 1951, using a Ferranti Mark 1 computer of the University of Manchester, checkers and chess programs were wrote where you could play against the computer. The field of American AI research was founded at a workshop at Dartmouth College in 1956. The attendees became the leaders of AI research in the 1960s. They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial Intelligence laboratories were set up at a number of British and US Universities in the latter 1950s and early 1960s.They had, however, underestimated the difficulty of the problem. Both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill and ongoing pressure from the U.S. Congress to fund more productive projects. Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether. The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.In the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.Many researchers began to doubt that the current practices would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into \"sub-symbolic\" approaches. Robotics researchers, such as Rodney Brooks, rejected \"representation\" in general and focussed directly on engineering machines that move and survive. Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic. But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others. In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics). By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\".Several academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field. For many specific tasks, other methods were abandoned.   Thought-capable artificial beings have appeared as storytelling devices since antiquity, and have been a persistent theme in science fiction.A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the \"Multivac\" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics; while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence. AI effect Artificial intelligence detection software – Software to detect AI-generated contentPages displaying short descriptions of redirect targets Artificial intelligence in healthcare – Overview of the use of artificial intelligence in healthcare     \"Artificial Intelligence\". Internet Encyclopedia of Philosophy. Thomason, Richmond. \"Logic and Artificial Intelligence\". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.\n",
      "\n",
      "Resulting Slices:\n",
      "Slice 1: [ 1  1  1  1  1  1  1  1  1  1  1 11  1  1  1  1  1  1  1  3  1  1  1  1\n",
      "  3  1  3  1  1  1  1  1  1  1  1  1  1  1  1  3  1  1  3  1  1  2  3  1\n",
      "  2  1  1  2  2  2  1  2  2  1  1  1  1  1  1  1  1  4  1  2  1  1  1  1\n",
      "  1  1  1  1  2  2  1  2  1  2  1  1  1  2  1  1  1  2  1  1  1  1  1  1\n",
      "  1  1  4  1  1  2]\n",
      "Slice 2: [ 2  1  1  1  1  1  1  1  1  1  1  4  1  5  3  1  1  1  3  1  1  1  2  1\n",
      "  2  1  1  1  2  1  1  7  1  1  1  1  1  1  1  1  1  1  1  2  1  1  2  1\n",
      "  2  1  1  1  1  1  6  2  2  2  3  1  3  1  2  1  1  2  1  1  2  1  1  2\n",
      "  4  1  2  2  1  1  1  1  1  1 17  1  2  1  2  1  2  4  1  1  2  1  2  1\n",
      "  1  1  1  1  4  1]\n",
      "Slice 3: [ 1  1  2  1  1  1  3  1  1  1  1  2  3  4  1  1  1  3  1  1  1  1  1  1\n",
      "  1  1  1  1  1  2  2  1  1  3  1  1  1  1  2  4  3  2  1  3  1  1  1  1\n",
      "  1  1  3  1  1  3  1  1  1  1  2  1  2  1  1  1  1  2  3  1  1  1  7  1\n",
      "  1  1  1  1  1  1  1  2  4 14  1  1  1  1  1  1  3  2  1  2  1  3  1  2\n",
      "  2  1  1  1  1  1]\n",
      "Slice 4: [1 1]\n"
     ]
    }
   ],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "def get_wikipedia_documents(topic, num_paragraphs=3):\n",
    "    wiki_wiki = wikipediaapi.Wikipedia('en', extract_format=wikipediaapi.ExtractFormat.WIKI, headers={'User-Agent': 'emilalizada0@gmail.com'})\n",
    "\n",
    "    page_py = wiki_wiki.page(topic)\n",
    "\n",
    "    if not page_py.exists():\n",
    "        return None\n",
    "\n",
    "    paragraphs = []\n",
    "    for section in page_py.sections:\n",
    "        paragraphs.extend(section.text.split('\\n')[:num_paragraphs])\n",
    "\n",
    "    return ' '.join(paragraphs)\n",
    "\n",
    "\n",
    "geographical_topics = [\"Geography\", \"Sea\", \"Ocean\", \"Longitude\", \"Meteorology\", \"Climate\"]\n",
    "non_geographical_topics = [\"Artificial intelligence\", \"Computer Science\", \"Medical\", \"History\"]\n",
    "geographical_documents = []\n",
    "non_geographical_documents = []\n",
    "\n",
    "# Fetch documents for geographical topics\n",
    "for topic in geographical_topics:\n",
    "    document = get_wikipedia_documents(topic)\n",
    "    if document:\n",
    "        geographical_documents.append(document)\n",
    "    else:\n",
    "        print(f\"Could not retrieve document for {topic}\")\n",
    "\n",
    "# Fetch documents for non-geographical topics\n",
    "for topic in non_geographical_topics:\n",
    "    document = get_wikipedia_documents(topic)\n",
    "    if document:\n",
    "        non_geographical_documents.append(document)\n",
    "    else:\n",
    "        print(f\"Could not retrieve document for {topic}\")\n",
    "\n",
    "# Displaying\n",
    "print(\"Geographical Documents:\")\n",
    "for i, document in enumerate(geographical_documents, start=1):\n",
    "    print(f\"Document {i} ({geographical_topics[i-1]}):\")\n",
    "    print(document)\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "print(\"\\nNon-Geographical Documents:\")\n",
    "for i, document in enumerate(non_geographical_documents, start=1):\n",
    "    print(f\"Document {i} ({non_geographical_topics[i-1]}):\")\n",
    "    print(document)\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# Select one document from each category for NLP pipeline\n",
    "sample_input1 = geographical_documents[0] if geographical_documents else None\n",
    "sample_input2 = non_geographical_documents[0] if non_geographical_documents else None\n",
    "\n",
    "if sample_input1:\n",
    "    result_slices1 = nlp_pipeline(sample_input1)\n",
    "    print(\"Input Text (Geographical):\")\n",
    "    print(sample_input1)\n",
    "    print(\"\\nResulting Slices:\")\n",
    "    for i, slice in enumerate(result_slices1, start=1):\n",
    "        print(f\"Slice {i}: {slice}\")\n",
    "\n",
    "if sample_input2:\n",
    "    result_slices2 = nlp_pipeline(sample_input2)\n",
    "    print(\"Input Text (Non-Geographical):\")\n",
    "    print(sample_input2)\n",
    "    print(\"\\nResulting Slices:\")\n",
    "    for i, slice in enumerate(result_slices2, start=1):\n",
    "        print(f\"Slice {i}: {slice}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words for Slices Below Standard Size:\n",
      "Slice 1: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 2 3 1 1\n",
      " 1 1 1 1 7 1 1 1 1 1 1 1 1 3 1 1 1 1 3 3 2 1 4 1 1 1 1 1 1 1 1 4 1 1 1 1 1\n",
      " 4 1 1 2 2 1 2 6 1 1 1 3 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1]\n",
      "Slice 2: [ 1  1  1  2  2  1  1  1  4  3  1  1  2  1  2  1  1  1  1  1  1  1  2  1\n",
      "  1  2  1  4  3  1  1  1  1  1  1  2  1  8  1  3  1  2  1  1  1  1  1  1\n",
      "  4  1  1  1  1  2  1  1  2  1  1  1  1  1  1  2  1  5  1  1  2  1  1  1\n",
      "  1  1  2  3  1  1  1  1  1  2 20 32  2  1  1  1  3  1  1  1  1  1  1  2\n",
      "  1  2  2  7  1]\n",
      "Slice 3: [2 2 1 1 2 1 4 1 1 1 3 2 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1\n",
      " 1 1 3 1 1 2 1 4 1 1 2 8 2 1 2 2 1 1 1 1 3 1 1 2 1 1 2 5 1 4 1 1 1 1 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 4 1 4 6 1 2 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Slice 4: [1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 3 3 1 1 1 2 1 1 1 1 3 1 5 1 1 1\n",
      " 1 2 1 5 1 1 2 1 1 1 2 1 1 5 1 1 1 2 1 1 1 1 1 1 1 1 3 1 1 3 1 2 2 1 2 2 1\n",
      " 1 1 1 1 1 1 1 1 6 1 1 1 1 1 1 1 1 1 1 1 6 2 1 1 1 1 1]\n",
      "Slice 5: [1 2 1]\n",
      "\n",
      "Bag of Words for Slices Above Standard Size:\n",
      "Slice 1: [100 100 100 100 100 100 100 100 100 100 100 100 100 100 200 100 100 100\n",
      " 100 100 100 200 100 100 100 100 100 100 100 100 200 200 100 200 300 100\n",
      " 100 100 100 100 100 700 100 100 100 100 100 100 100 100 300 100 100 100\n",
      " 100 300 300 200 100 400 100 100 100 100 100 100 100 100 400 100 100 100\n",
      " 100 100 400 100 100 200 200 100 200 600 100 100 100 300 200 100 100 100\n",
      " 200 100 100 100 100 100 100 100 100 200 100 100]\n",
      "Slice 2: [100 100 200 100 400 100 100 100 300 200 100 100 100 100 100 100 100 100\n",
      " 200 100 100 200 100 100 100 100 100 200 200 100 200 100 200 100 100   1\n",
      "  99 100 300 100 100 200 100 400 100 100 200 800 200 100 200 200 100 100\n",
      " 100 100 300 100 100 200 100 100 200 500 100 400 100 100 100 100 100 100\n",
      " 100 100 100 100 200 100 100 100 100 100 400 100 400 600 100 200 100 100\n",
      " 100 100 100 100 100 100 100 100 100 100 100 100]\n",
      "Slice 3: [100 100 100 100 200 100 100 100 100 100 100 100 100 200 100 100 100 100\n",
      " 100 300 300 100 100 100 200 100 100 100 100 300 100 500 100 100 100 100\n",
      " 200 100 500 100 100 200 100 100 100 200 100 100 500 100 100 100 200 100\n",
      " 100 100 100 100 100 100 100 300 100 100 300 100 200 200 100 200 200 100\n",
      " 100 100 100 100 100 100 100 100 600 100 100 100 100 100 100 100 100 100\n",
      " 100 100 600 200 100 100 100 100 100 100 200 100]\n",
      "\n",
      "Cosine Distances for Slices Below Standard Size:\n",
      "Distance between Slice 1 and Slice 2: 0.6312443452426595\n",
      "Distance between Slice 2 and Slice 3: 0.5359068797754543\n",
      "Distance between Slice 3 and Slice 4: 0.38741739982321166\n",
      "Distance between Slice 4 and Slice 5: 0.05719095841793642\n",
      "\n",
      "Cosine Distances for Slices Above Standard Size:\n",
      "Distance between Slice 1 and Slice 2: 0.3369528443624251\n",
      "Distance between Slice 2 and Slice 3: 0.37771476790651926\n",
      "\n",
      "Testing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_cosine_distance(slice1, slice2):\n",
    "    # Ensure the input slices are NumPy arrays\n",
    "    vector1 = np.array(slice1)\n",
    "    vector2 = np.array(slice2)\n",
    "\n",
    "    common_dimensions = min(len(vector1), len(vector2))\n",
    "    vector1 = vector1[:common_dimensions]\n",
    "    vector2 = vector2[:common_dimensions]\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_matrix = cosine_similarity(vector1.reshape(1, -1), vector2.reshape(1, -1))\n",
    "    cosine_distance = 1 - similarity_matrix[0, 0]\n",
    "\n",
    "    return cosine_distance\n",
    "\n",
    "# Testing with Different Inputs\n",
    "cosine_distance_threshold = 0.2\n",
    "\n",
    "#Geographical\n",
    "input_below_standard_size = sample_input1\n",
    "slices_below_standard_size = nlp_pipeline(input_below_standard_size)\n",
    "\n",
    "#Geographical, Above Standard Size\n",
    "input_above_standard_size = sample_input1 * 100\n",
    "slices_above_standard_size = nlp_pipeline(input_above_standard_size)\n",
    "\n",
    "# Verify bag-of-words representations for slices\n",
    "print(\"Bag of Words for Slices Below Standard Size:\")\n",
    "for i, slice in enumerate(slices_below_standard_size, start=1):\n",
    "    print(f\"Slice {i}: {slice}\")\n",
    "\n",
    "print(\"\\nBag of Words for Slices Above Standard Size:\")\n",
    "for i, slice in enumerate(slices_above_standard_size, start=1):\n",
    "    print(f\"Slice {i}: {slice}\")\n",
    "\n",
    "# Verify Cosine Distances for Adjacent Slices\n",
    "print(\"\\nCosine Distances for Slices Below Standard Size:\")\n",
    "for i in range(len(slices_below_standard_size) - 1):\n",
    "    distance = calculate_cosine_distance(slices_below_standard_size[i], slices_below_standard_size[i+1])\n",
    "    print(f\"Distance between Slice {i+1} and Slice {i+2}: {distance}\")\n",
    "\n",
    "print(\"\\nCosine Distances for Slices Above Standard Size:\")\n",
    "for i in range(len(slices_above_standard_size) - 1):\n",
    "    distance = calculate_cosine_distance(slices_above_standard_size[i], slices_above_standard_size[i+1])\n",
    "    print(f\"Distance between Slice {i+1} and Slice {i+2}: {distance}\")\n",
    "\n",
    "print(\"\\nTesting completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
